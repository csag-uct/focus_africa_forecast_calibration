{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769d138d-653b-4c75-a750-accc044f6b13",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "This annotated jupyter notebook is intended to provide training material for users of a system for seasonal hydrological forecast in the Shire River Basin - a climate service developed under funding from FOCUS Africa project. \n",
    "\n",
    "The notebook focuses on one of the processes involved in this sytem, namely the process of calibration of a probabilistic (an initial condition ensemble) seasonal forecast to the reference historical data.\n",
    "\n",
    "While it is intended as a training material, it assumes that the \"trainee\", or a user of this notebook has a basic understanding of:\n",
    "- seasonal forecasting concepts such as seasonal foreasting with dynamical models and in particular understanding of an initial condition ensemble forecast\n",
    "- statistical concepts such as probability, distributions, quantiles etc.\n",
    "- data processing using python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcb0d85-0570-43d0-b6fa-c26ac38ba3b0",
   "metadata": {},
   "source": [
    "test1\n",
    "\n",
    "<img src=\"https://web.csag.uct.ac.za/~wolski/focus_africa/training_material/forecast_malawi/figures/forecast_fig2.png\" />\n",
    "\n",
    "test2\n",
    "\n",
    "<img src=\"figures/forecast_fig2.png\" alt=\"framework2\" class=\"bg-primary mb-1\" width=\"500px\" />\n",
    "\n",
    "test3\n",
    "\n",
    "![test](figures/forecast_fig2.png)\n",
    "\n",
    "test 4\n",
    "\n",
    "![](forecast_fig2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af3bb4-4d76-4c38-8984-f35145746d22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A bit of a background\n",
    "Hydrological modelling for water resources in Malawi is done at Malawi DCCMS using a suite of three models:\n",
    "- rainfall-runoff model of catchment upstream from Lake Malawi\n",
    "- Lake Malawi water balance model\n",
    "- rainfall-runoff and river routing model for the Lower Shire River basin.\n",
    "\n",
    "The hydrological models were developed/calibrated with a bespoke gridded, daily rainfall and air temperature dataset that are a blend of CRU and observational data. This dataset covers only the historical period of 1981-2018. \n",
    "\n",
    "This hydrological modelling suite does not currently operate in a seasonal forecast mode, and thus there is scope for development and implementation of seasonal hydrological forecast where these three models are routinely run with forcing data from a seasonal climate forecast.\n",
    "\n",
    "The overall framework of the seasonal forecasting system is briefly described below, but the intention of this notebook is to present the processing of climate forecast data from a probabilistic climate forecast generated by a dynamical global climate model to the format suitable for forcing of the DCCMS hydrological model suite.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1a6b5-91e0-4b68-b99f-6f48422433af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adopted approach to implementing the DCCMS hydrological models in seasonal forecasting mode \n",
    "Overall framework for the operational seasonal hydrological forecast in the Lake Malawi Basin is illustrated in Fig. 1. In that, the hydrological forecast is issued every month and covers 6 monthly period starting on that month.\n",
    "<center>\n",
    "<img src=\"https://web.csag.uct.ac.za/~wolski/focus_africa/training_material/forecast_malawi/figures/forecast_fig1.png\" alt=\"framework1\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "</center>\n",
    "<center>\n",
    "<i>Fig. 1 Timing of hydrological model simulations in the seasonal hydrological forecasting system</i>\n",
    "</center>\n",
    "\n",
    "The hydrological forecast is based on forecast climate variables generated by an ensemble of dynamical models. The entire ensemble can be processed, or alternatively only selected models. Since the models generate a probabilistic ensemble forecast, even using one model will involve multiple hydrological simulations. The system requires the following simulations with the suite of hydrological models (Fig. 2):\n",
    "- Simulations to establish initial conditions for the forecast simulations. These simulations are based on a historical, observed time series of rainfall that spans from the beginning of record till the month prior to the date of issuing the forecast.\n",
    "- Simulations forced by forecast data. These are multiple runs of each model forced by an ensemble of time series of climatic variables derived from the raw forecast data through a statistical calibration procedure.\n",
    "\n",
    "Output of the hydrological simulations constitutes an ensemble of possible future hydrological states, and that is interpreted within a probabilistic framework - i.e. in terms of probabilities of exceedance etc.\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./figures/forecast_fig2.png\" alt=\"framework2\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "</center>\n",
    "<center>\n",
    "<i>Fig. 2 Schematic illustration of the outputs of the seasonal hydrological forecasting system</i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75d783-79d8-408d-a94a-bcce34782bfb",
   "metadata": {},
   "source": [
    "## Datastream underlying the hydrological forecasting system\n",
    "\n",
    "Fig. 3 illustrates the \"flow\" of data in the hydrological forecasting system. There are a number of steps involved:\n",
    "- download of climate forecast data\n",
    "- pre-processing (or homogeneization) of climate forecast data\n",
    "- integration of monitoring/observational data with historical hydrological model forcing data\n",
    "- downscaling and calibration of climate forecast data\n",
    "- running of the three hydrological models with monitoring/observational data and seasonal forecast data\n",
    "\n",
    "<b>This notebook describes only the process of forecast downscaling/calibration!</b>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://web.csag.uct.ac.za/~wolski/focus_africa/training_material/forecast_malawi/figures/forecast_fig3.png\" alt=\"framework3\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "</center>\n",
    "<center>\n",
    "<i>Fig. 3 Datastream underlying the hydrological forecasting system</i>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7718df6-8372-44d2-b5d0-b30e51a553b5",
   "metadata": {},
   "source": [
    "# Process of forecast downscaling & calibration\n",
    "\n",
    "<center>\n",
    "<img src=\"https://web.csag.uct.ac.za/~wolski/focus_africa/training_material/forecast_malawi/figures/forecast_fig4.png\" alt=\"framework4\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "</center>\n",
    "<center>\n",
    "<i>Fig. 4 Forecast downcaling and calibration</i>\n",
    "</center>\n",
    "\n",
    "## Monthly data\n",
    "Calibration of the monthly data using the IoV approach against observed monthly data (hydrological model input aggregated to monthly totals) (Johnson and Bowler, 2009).\n",
    "The IoV approach is suited to ensure the condition of ensemble consistency (as described above, i.e. that the observations are statistically indistinguishable from a member of the forecast ensemble). That condition translates into two requirements 1) that the MSE of the ensemble mean is equal to climatological mean of ensemble variance (i.e. mean of variances of ensemble members of all forecasts of a given month at a given lead time), and 2) that climatological variance of an ensemble member is equal to the climatological variance of observations. This is achived by a set of linear transformation of the ensemble data as per Johnson and Bowler (2009). The calibration is implemented at each grid point, for each target month at each forecast lead time. \n",
    "\n",
    "## Daily data\n",
    "Bias correction at daily time scale is carried out using a modified quantile-quantile mapping approach. The modification accounts for the requirement that daily bias-corrected data should yield monthly total corresponding to the calibrated monthly value. In order to achieve that - an iterative procedure of adjustment of quantiles is implemented (Fig. 5). This allows for achieving agreement between daily and monthly totals, and adherence of the daily data to the observational distribution. \n",
    "\n",
    "<center>\n",
    "<img src=\"https://web.csag.uct.ac.za/~wolski/focus_africa/training_material/forecast_malawi/figures/forecast_fig5.png\" alt=\"framework5\" class=\"bg-primary mb-1\" width=\"500px\">\n",
    "</center>\n",
    "<center>\n",
    "<i>Fig. 5 Bias-correcting of daily data</i>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8529d8-9ffc-41b2-99f9-60d62f4f196f",
   "metadata": {},
   "source": [
    "# Prerequisites for the process implemented in this notebook\n",
    "\n",
    "We do not implement here the entire process of generation of the seasonal hydrological forecast as illustrated in Fig. 3. Rather, we focus only on the Downscaling/Calibration step.\n",
    "\n",
    "In order to implement this step - a number of pre-requisites are needed, namely:\n",
    "- raw forecast data have to be downloaded from the source\n",
    "- the raw data have to be harmonized to be compatible with this script. This involves:\n",
    "    - individual forecasts have to be stored in separate netcdf files\n",
    "    - the netcdf data file has to have a particular structure:\n",
    "        - forecast data are stored in a four-dimensional array, with the following dimensions order: time,member,latitude,longitude\n",
    "        - variable names have to be harmonized - this script uses <i>latitude</i> and <i>longitude</i> for latitude and longitude, <i>time</i> for time variable, <i>pr</i> for precipitation and <i>member</i> for ensemble member variable\n",
    "        - the time variable encodes date/time of the period for which forecast is issued. This is feasible only if data from an individual forecast, i.e. a forecast issued on a particular date, are stored in an individual file.\n",
    "    - forecast data have to be regrided to the same domain and spatial grid size as the observed reference data\n",
    "    - directory structure and file naming convention has to be aligned with those adopted here (described below)\n",
    "    - we consider that the forecast spans 6 months from the issuance date\n",
    "    - for forecast - at least daily data have to be available. Monthly data are required, but it can be calculated from daily, if not pre-calculated during harmonization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d462195-0ae5-43b5-baeb-ae9d0902c1d2",
   "metadata": {},
   "source": [
    "## Data model\n",
    "The sample data provided with this notebook are created under a particular \"data model\", i.e. a schematic that governs the directory structure and file naming conventions adopted to store the data. \n",
    "\n",
    "That data model requires some explanation before we proceed.\n",
    "\n",
    "\n",
    "### Directory structure:\n",
    "\n",
    "The data are stored in the following tree of directories:\n",
    "\n",
    "<i>\\[data_dir\\]/\\[ensemble\\]/\\[model\\]/\\[basetime\\]/\\[domain\\]/\\[variable\\]</i>\n",
    "\n",
    "\n",
    "\n",
    "<b><i>data_dir</i></b>\n",
    "\n",
    "This is the directory in which harmonized forecast data are stored. That directory is specific to the HPC on which the system operates. This allows easy adaptation of the code if the system is ported or set-up on a different HPC, as well as setting up this notebook to work with sample data provided here. \n",
    "\n",
    "<b><i>ensemble, model</i></b>\n",
    "\n",
    "These define the sub-directory structure, so that data for a particular model sourced from a particular ensemble are stored in a particular directory, e.g. data for the ECMWF's SEAS5.1 will be stored in:\n",
    "\n",
    "<i>\\[root_dir\\]/ECMWF/SEAS51/</i>\n",
    "\n",
    "<b><i>basetime</i></b>\n",
    "\n",
    "Basetime denotes the temporary resolution of data. Data at monthly basetime, or resolution are stored in:\n",
    "\n",
    "<i>\\[root_dir\\]/ECMWF/SEAS51/mon/</i>\n",
    "\n",
    "while data at daily resolution are stored in:\n",
    "\n",
    "<i>\\[root_dir\\]/ECMWF/SEAS51/day/</i>\n",
    "\n",
    "<b><i>domain</i></b>\n",
    "\n",
    "Domain defines a region over which data are processed, which allows for creating separate datastreams for different regions. In our case, data are stored in:\n",
    "\n",
    "<i>\\[root_dir\\]/ECMWF/SEAS51/mon/malawi/</i>\n",
    "\n",
    "<b><i>variable</i></b>\n",
    "\n",
    "This level of directory structure allows for storing data for various variables separately. In our case we process only precipitation data, so we will store them in: \n",
    "\n",
    "<i>\\[root_dir\\]/ECMWF/SEAS51/mon/malawi/pr/</i>\n",
    "\n",
    "### File naming convention:\n",
    "\n",
    "We adopt the following file naming convention:\n",
    "\n",
    "<i>\\[var\\]_\\[basetime\\]_\\[ensemble\\]_\\[model\\]_\\[datatype\\]_\\[year\\]\\[month\\].nc</i>\n",
    "\n",
    "so data for monthly rainfall forecast issued in December 2023 will be stored in:\n",
    "\n",
    "<i>pr_mon_ECMWF_SEAS51_fcst_202312.nc</i>\n",
    "\n",
    "of course placed in an appropriate directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b10e139-ea2f-416a-8a4e-46ac61b807f9",
   "metadata": {},
   "source": [
    "# Finally, we can start coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d58c39-3964-468f-9e3c-390b6f4b8459",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c534370-62cc-46e1-b12c-57cb1dbe92bd",
   "metadata": {},
   "source": [
    "Firstly, we have to load all the python libraries we going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8944a847-7fd1-4e84-9d91-bdbde6b09264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os, glob, sys, calendar\n",
    "import scipy.stats as stat\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aa19e-1d49-4e58-b001-46c94e67422f",
   "metadata": {},
   "source": [
    "Now, we can set up input and output data files. \n",
    "The code in this notebook processes a forecast from a single seasonal forecasting system, namely ECMWF's SEAS5.1. \n",
    "In order to make the code universal, i.e. for it to be able to be quickly adapted to process data from a different forecasting system, we introduce a number of variables that identify the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57778114-7551-4802-ae46-c589dd4a2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ensemble variable is introduced to allow for differentiation \n",
    "# between different sources of forecast data. In our notation, ECMWF describes a multi-model \n",
    "# ensemble distributed through the Copernicus Data Store.\n",
    "ensemble=\"ECMWF\"\n",
    "\n",
    "#this is code of the particular model from the ensemble. \n",
    "model=\"SEAS51\"\n",
    "\n",
    "# This is the number of the month from which the forecast will be processed. \n",
    "# Note that \"normally\" python indexes variables starting from 0, \n",
    "# but the number that is used to define a calendar month is indexed from 1, \n",
    "# i.e. January is the first month of the year, and corresponds to the value of 1  \n",
    "fcstmonth=10\n",
    "\n",
    "# This is the year from which the forecast will be processed.\n",
    "fcstyear=2023\n",
    "\n",
    "# This is variable that is going to be processed. \n",
    "# This notebook describes processing of rainfall only\n",
    "variable=\"pr\"\n",
    "\n",
    "# This defines a domain, or a region over which data are processed\n",
    "domain=\"malawi\"\n",
    "\n",
    "#finally, a variable that controls whether or not existing output files are overwritten\n",
    "overwrite=True\n",
    "\n",
    "# this is definition of trace rainfall, i.e. amount which will be treated as 0 in calculations\n",
    "traceday=0.1\n",
    "tracemon=5\n",
    "\n",
    "# iteration parameters used during the iterative adjustement of daily data\n",
    "#convcrit expresses fraction difference betweeen monthly total from adjusted daily data and that in calibrated monthly data\n",
    "convcrit=0.01\n",
    "maxiter=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1c9da-40b4-42d1-9d09-b754bf400ffa",
   "metadata": {},
   "source": [
    "We will subsequently derive some \"secondary\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a924fbe-f8d3-4a14-9a43-6560183f3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is abbreviated name of the forecast month\n",
    "fcstmonth_abbr=calendar.month_abbr[fcstmonth]\n",
    "\n",
    "# This is a two-digit code for the forecast month. \n",
    "# It is introduced here because input files are named using numerical value of the month\n",
    "# in a two-digit format, i.e. the file name for January will have \n",
    "# the month coded as 01 rather than 1 \n",
    "fcstmonth_code=str(fcstmonth).zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d08c1c20-6861-4e72-9169-b10e15a34a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the root directory in which calibrated forecast data from all ensembles and models are stored\n",
    "harmonizedfcst_root=\"/terra/projects/focus-africa/fcst_malawi/data/seasonal\"\n",
    "harmonizedfcst_root=\"/terra/projects/focus-africa/fcst_malawi/data/seasonal\"\n",
    "\n",
    "# This is the root directory in which calibrated forecast data from all ensembles and models are stored\n",
    "calibratedfcst_root=\"/terra/projects/focus-africa/fcst_malawi/data/seasonal-calibrated\"\n",
    "\n",
    "# These are directories that store data for a particular ensemble and model\n",
    "harmonizedfcstday_dir=\"{}/{}/{}/day/{}/{}\".format(harmonizedfcst_root,ensemble,model,domain,variable)\n",
    "calibratedfcstday_dir=\"{}/{}/{}/day/{}/{}\".format(calibratedfcst_root,ensemble,model,domain,variable)\n",
    "harmonizedfcstmon_dir=\"{}/{}/{}/mon/{}/{}\".format(harmonizedfcst_root,ensemble,model,domain,variable)\n",
    "calibratedfcstmon_dir=\"{}/{}/{}/mon/{}/{}\".format(calibratedfcst_root,ensemble,model,domain,variable)\n",
    "\n",
    "# These are input files - monthly and daily\n",
    "harmonizedfcstmon_file=\"{}/{}_mon_{}_{}_{}{}.nc\".format(harmonizedfcstmon_dir,variable,ensemble,model,fcstyear,fcstmonth_code)\n",
    "harmonizedfcstday_file=\"{}/{}_day_{}_{}_{}{}.nc\".format(harmonizedfcstday_dir,variable,ensemble,model,fcstyear,fcstmonth_code)\n",
    "\n",
    "# These are output files - monthly and daily\n",
    "calibratedfcstmon_file=\"{}/{}_mon_{}_{}_fcst-iov_{}{}.nc\".format(calibratedfcstmon_dir,variable,ensemble,model,fcstyear,fcstmonth_code)\n",
    "calibratedfcstday_file=\"{}/{}_day_{}_{}_fcst-iov_{}{}.nc\".format(calibratedfcstday_dir,variable,ensemble,model,fcstyear,fcstmonth_code)\n",
    "\n",
    "# These are input reference data files\n",
    "referencemon_file=\"../data/obs_malawi/{}_mon_obs.nc\".format(variable)\n",
    "referenceday_file=\"../data/obs_malawi/{}_day_obs.nc\".format(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e57885-be1c-4898-ac7f-e21de591110d",
   "metadata": {},
   "source": [
    "Now we will perform check for output files and directories - perhaps they already exist, i.e. were calculated before, and there is nothing to do? Unless we want to overwrite the old files, that is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0f40326c-5ddb-4b59-9ffe-a141d97fd1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data availability for forecast for Oct 2023:\n",
      "\n",
      "Daily output file: /terra/projects/focus-africa/fcst_malawi/data/seasonal-calibrated/ECMWF/SEAS51/day/malawi/pr/pr_day_ECMWF_SEAS51_fcst-iov_202310.nc\n",
      "exists\n",
      "but overwrite if True. Processing...\n",
      "\n",
      "Monthly output file: /terra/projects/focus-africa/fcst_malawi/data/seasonal-calibrated/ECMWF/SEAS51/mon/malawi/pr/pr_mon_ECMWF_SEAS51_fcst-iov_202310.nc\n",
      "exists\n",
      "but overwrite if True. Processing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking data availability for forecast for {} {}:\\n\".format(fcstmonth_abbr, fcstyear))\n",
    "\n",
    "print(\"Daily output file: {}\".format(calibratedfcstday_file))\n",
    "if os.path.exists(calibratedfcstday_file):\n",
    "    print(\"exists\")\n",
    "    if overwrite==False:\n",
    "        print(\"but overwrite if False. Nothing to process. Exiting...\\n\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print(\"but overwrite if True. Processing...\\n\")\n",
    "else:\n",
    "    print(\"does not exist. Processing...\\n\")\n",
    "\n",
    "print(\"Monthly output file: {}\".format(calibratedfcstmon_file))\n",
    "if os.path.exists(calibratedfcstmon_file):\n",
    "    print(\"exists\")\n",
    "    if overwrite==False:\n",
    "        print(\"but overwrite if False. Nothing to process. Exiting...\\n\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print(\"but overwrite if True. Processing...\\n\")\n",
    "else:\n",
    "    print(\"does not exist. Processing...\\n\")\n",
    "    \n",
    "if not os.path.exists(calibratedfcstday_dir):\n",
    "    print(\"Output directory {} does not exist. It has to be created manually. Exiting...\\n\".format(calibratedfcstday_dir))\n",
    "    sys.exit()\n",
    "\n",
    "if not os.path.exists(calibratedfcstmon_dir):\n",
    "    print(\"Output directory {} does not exist. It has to be created manually. Exiting...\".format(calibratedfcstmon_dir))\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e29a66-20b4-4887-9e93-72590dac9fd7",
   "metadata": {},
   "source": [
    "Now we will perform check for all necessary input files and directories.\n",
    "Note that downscaling/calibration process requires:\n",
    "- historical observational reference data\n",
    "- historical forecast data (retrospective forecast)\n",
    "- current harmonized (uncalibrated) forecast data\n",
    "\n",
    "All of these data has to be available at daily and monthly time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "15a14826-9308-4b2a-afa3-c1d5bfc52347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking observational reference period files\n",
      "Reference observational data file ../data/obs_malawi/pr_mon_obs.nc exists. Proceeding...\n",
      "Reference observational daily data file ../data/obs_malawi/pr_day_obs.nc exists. Proceeding...\n",
      "\n",
      "Checking retrospective forecast files for Oct\n",
      "Found harmonized monthly files for 37 years\n",
      "Found harmonized daily files for 37 years\n",
      "\n",
      "Checking current forecast files for Oct 2023\n",
      "Monthly input file: /terra/projects/focus-africa/fcst_malawi/data/seasonal/ECMWF/SEAS51/mon/malawi/pr/pr_mon_ECMWF_SEAS51_202310.nc\n",
      "exists. Proceeding...\n",
      "Daily input file: /terra/projects/focus-africa/fcst_malawi/data/seasonal/ECMWF/SEAS51/day/malawi/pr/pr_day_ECMWF_SEAS51_202310.nc\n",
      "exists. Proceeding...\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking observational reference period files\")\n",
    "\n",
    "#reference files\n",
    "if not os.path.exists(referencemon_file):\n",
    "    print(\"Reference observational data file {} does not exist. exiting...\\n\".format(referencemon_file))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Reference observational data file {} exists. Proceeding...\".format(referencemon_file))\n",
    "if not os.path.exists(referenceday_file):\n",
    "    print(\"Reference observational daily data file {} does not exist. exiting...\\n\".format(referenceday_file))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Reference observational daily data file {} exists. Proceeding...\\n\".format(referenceday_file))\n",
    "\n",
    "    \n",
    "#retrospective forecast files\n",
    "print(\"Checking retrospective forecast files for {}\".format(fcstmonth_abbr))\n",
    "\n",
    "pattern=\"{}/{}_mon_{}_{}_*{}.nc\".format(harmonizedfcstmon_dir,variable,ensemble,model,fcstmonth_code)\n",
    "harmonizedfcstmon_files=glob.glob(pattern)\n",
    "if len(harmonizedfcstmon_files)==0:\n",
    "    print(\"There are no harmonized files matching pattern {}. exiting...\".format(pattern))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Found harmonized monthly files for {} years\".format(len(harmonizedfcstmon_files)))\n",
    "    \n",
    "pattern=\"{}/{}_day_{}_{}_*{}.nc\".format(harmonizedfcstday_dir,variable,ensemble,model,fcstmonth_code)\n",
    "harmonizedfcstday_files=glob.glob(pattern)\n",
    "if len(harmonizedfcstday_files)==0:\n",
    "    print(\"There are no harmonized files matching pattern {}. exiting...\".format(pattern))\n",
    "    sys.exit()\n",
    "else:\n",
    "    print(\"Found harmonized daily files for {} years\\n\".format(len(harmonizedfcstday_files)))\n",
    "\n",
    "    \n",
    "print(\"Checking current forecast files for {} {}\".format(fcstmonth_abbr, fcstyear))\n",
    "\n",
    "print(\"Monthly input file: {}\".format(harmonizedfcstmon_file))\n",
    "calc_harmonizedfcstmon=False\n",
    "if os.path.exists(harmonizedfcstmon_file):\n",
    "    print(\"exists. Proceeding...\")\n",
    "else:\n",
    "    print(\"Is missing. It will be calculated from daily data\\n\")\n",
    "    calc_harmonizedfcstmon=True\n",
    "    \n",
    "print(\"Daily input file: {}\".format(harmonizedfcstday_file))\n",
    "if os.path.exists(harmonizedfcstday_file):\n",
    "    print(\"exists. Proceeding...\")\n",
    "else:\n",
    "    print(\"missing. Calculations cannot proceed. Exiting\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ba4fc-f3cb-48cd-b304-f2122cf6b391",
   "metadata": {},
   "source": [
    "# Calculating monthly integration for current forecast at daily time step, if necessary\n",
    "\n",
    "Here we will calculate monthly total from daily data. This is a relatively simple operation that uses the xarray resample function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a470033-54e9-4400-96a0-4a99849b10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_harmonizedfcstmon==True:\n",
    "    # opening daily file\n",
    "    ds_day=xr.open_dataset(harmonizedfcstday_file)\n",
    "    #calculating monthly total\n",
    "    ds_mon=ds_day.resample(time=\"M\").sum()\n",
    "    # adding unit attribute\n",
    "    ds_mon[variable].attrs[\"unit\"]=\"mm/month\"\n",
    "    # adding description\n",
    "    ds_mon.attrs[\"description\"]=\"derived by integration of daily data to monthly total\"\n",
    "    #saving to monthly netcdf file\n",
    "    ds_mon.to_netcdf(harmonizedfcstmon_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b4c4c3-8b80-455e-86b4-959c370549fb",
   "metadata": {},
   "source": [
    "# Downscaling/calibration at monthly time step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988cf439-50a9-4724-9fac-b69f6c0ea6a4",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "Calibration at monthly time scale is here carried out using an approach called Inflation of Variance. That approach is described by...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3ed3b-261d-4be0-bb76-449ca9260f44",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The IoV is implemented using two functions - calibrate_iov_single and calibrate_iov_loocv\n",
    "\"loocv\" stands for leave one out cross-validation. That function calibrates data for given forecast  based on statistics derived from all other forecsts issued for that forecast's month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9aa92af-4be7-4390-93a7-9845016b0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_iov_single(_fcst,_obs,_target):\n",
    "    if np.sum(np.isnan(_fcst[:,0]))==0:\n",
    "        _fcst = _fcst[~np.isnan(_obs),:]\n",
    "        _obs = _obs[~np.isnan(_obs)]\n",
    "        \n",
    "        #corecting bias in mean of the forecast\n",
    "        _fmean=np.mean(np.nanmean(_fcst,axis=1))\n",
    "        _fcst=_fcst-_fmean\n",
    "        _target=_target-_fmean\n",
    "        _omean=_obs.mean()\n",
    "        _obs=_obs-_omean\n",
    "        \n",
    "        _f_t=np.nanmean(_fcst,axis=-1).reshape(-1,1) # \"ensemble mean\" at time steps (T) (1a)\n",
    "        _epsil_t=_fcst-_f_t #anomalies (T,M)\n",
    "        _sigma2_t=(np.nanmean((_fcst-_f_t)**2, axis=-1)) #eq. 1b ensemble variance at time steps (T)\n",
    "        _sigma2_x=np.var(_obs) #eq. 2a \"climatological variance of true state\" (1 value)\n",
    "        _mu_f=np.mean(_f_t) #grand mean of the ensemble (1 value)\n",
    "        _mu_x=np.mean(_obs) #mean of observations (1 value)\n",
    "        _sigma2_f2b=np.mean((_f_t-_mu_f)**2) #eq. 2b - variance of ensemble mean (one value)\n",
    "        _sigma2_f2c=np.mean(np.nanmean((_fcst-_mu_f)**2,axis=-1)) #2c - mean variance of ensemble #(one value)\n",
    "        _sigma2_e=np.mean(_sigma2_t) #Eq. 2d average ensemble variance (one value)\n",
    " \n",
    "        _rho=stat.pearsonr(_f_t.flatten(),_obs)[0] #they are adjusted earlier to cover the same time\n",
    "        _alpha=abs(_rho)*(_sigma2_x**0.5)/(_sigma2_f2b**0.5) #eq. 7a 2b is the correct one!!!\n",
    "        _beta2=(1-_rho**2)*_sigma2_x/_sigma2_e #eq. 7b\n",
    "        \n",
    "        #this is for target\n",
    "        _f_t_target=np.nanmean(_target,axis=-1).reshape(-1,1)\n",
    "        _epsil_t_target=_target-_f_t_target #anomalies (T,M)\n",
    "        _target_calib=_alpha*_f_t_target+(_beta2**0.5)*_epsil_t_target\n",
    "        _target_calib=_target_calib+_omean\n",
    "        \n",
    "        return(_target_calib)\n",
    "    else:\n",
    "        cont=True\n",
    "        _output=np.copy(_target)\n",
    "        _output[:]=np.nan\n",
    "        return(_output)\n",
    "    \n",
    "def calibrate_iov_loocv(_fcst,_obs):\n",
    "    if np.sum(np.isnan(_fcst[:,0]))==0:\n",
    "        _output=np.copy(_fcst)\n",
    "        _output[:]=np.nan\n",
    "        for i in range(_fcst.shape[0]):\n",
    "            _target_temp=_fcst[i,:]\n",
    "            _fcst_temp=np.delete(_fcst,i,0)\n",
    "            _obs_temp=np.delete(_obs,i,0)\n",
    "            _output[i,:]=calibrate_iov_single(_fcst_temp,_obs_temp,_target_temp)\n",
    "        return(_output)\n",
    "    else:\n",
    "        _output=np.copy(_fcst)\n",
    "        _output[:]=np.nan        \n",
    "        return(_output)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e9321c-b45e-4f40-8d31-5ec378848283",
   "metadata": {},
   "source": [
    "### Reading monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8944f1fc-f6e0-4c24-8e8f-5131589edb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading monthly reference data from: ../data/obs_malawi/pr_mon_obs.nc\n",
      "reading monthly retro forecast data\n"
     ]
    }
   ],
   "source": [
    "print(\"reading monthly reference data from: {}\".format(referencemon_file))\n",
    "refmon=xr.open_dataset(referencemon_file)[variable]\n",
    "\n",
    "print(\"reading monthly retro forecast data\")\n",
    "fcstmon=xr.open_mfdataset(harmonizedfcstmon_files).load()[variable]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e1687-a14d-440c-9c73-9bcc7104c5f2",
   "metadata": {},
   "source": [
    "### Calibrating\n",
    "\n",
    "Code below loops through lead times, because calibration has to be done for a particular target month at a particular lead time\n",
    "calibration is done using apply_ufunc which basically iterates though individual grid cells and implements the calibrate_loocv function on each grid cell\n",
    "before the apply_ufunc is iplemented, some data processing is done:\n",
    "- we find out the calendar month of the target month, i.e. month at give lead time\n",
    "- we select data for that month from the reference dataset\n",
    "- also, we select all data for that month from the retrospective forecasts. Mind that retrospective forecast were read only for the currently analysed issuance month. In this way, retro forecast data for target month are all at the same leadtime\n",
    "- subsequently, we align the reference and reforecast data along the time axis. This is done by: \n",
    "    - creating an empty \"placeholder\" array for reference data of the same spatial and temporal extent as the reforecast data.\n",
    "    - finding times when the actual reference data overlaps that \"placeholder\"\n",
    "    - filling \"placeholder\" with data from the reference dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7031bebc-fb54-4b22-9c98-79a743ce9fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrating at 0 month leadtime\n",
      "calibrating at 1 month leadtime\n",
      "calibrating at 2 month leadtime\n",
      "calibrating at 3 month leadtime\n",
      "calibrating at 4 month leadtime\n",
      "calibrating at 5 month leadtime\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# since we are iterating through lead times, the individual lead time outputs are stored into a list. \n",
    "# That list will be converted to xarray once all is calculated\n",
    "fcstmoncalib=[]\n",
    "\n",
    "#iterating through leadtimes\n",
    "for leadtime in range(6):\n",
    "    #this will be calendar month of the target month at current lead time \n",
    "    calendarmon=fcstmon.time[leadtime].dt.month.data\n",
    "    \n",
    "    # selecting data for the target month only\n",
    "    refmonselected=refmon.sel(time=refmon.time.dt.month==calendarmon)\n",
    "    fcstmonselected=fcstmon.sel(time=fcstmon.time.dt.month==calendarmon)\n",
    "    \n",
    "    #creating a placeholder for reference data\n",
    "    refmonarray=fcstmonselected[:,0,:,:].copy(deep=True)\n",
    "    \n",
    "    #filling it with nan\n",
    "    refmonarray[:]=np.nan\n",
    "    \n",
    "    # finding dates in reference data for which reforecast is available\n",
    "    overlap=[x for x in refmonselected.time.data if x in fcstmonselected.time.data]\n",
    "    \n",
    "    #this will have the same dimensions as fcstselected, and will be filled with reference data, when available, otherwise nan\n",
    "    refmonoverlap=refmonselected.sel(time=overlap)\n",
    "    \n",
    "    #this corresponds to the coverage of forecast, but has data only where obs data are available\n",
    "    refmonarray.loc[dict(time=refmonoverlap.time)]=refmonoverlap\n",
    "    \n",
    "\n",
    "    #calibrating\n",
    "    print(\"calibrating at {} month leadtime\".format(leadtime))\n",
    "    temp=xr.apply_ufunc(\n",
    "        calibrate_iov_loocv, \n",
    "        fcstmonselected.load(),\n",
    "        refmonarray,\n",
    "        input_core_dims=[[\"time\",\"member\"],[\"time\"]],\n",
    "        vectorize=True,\n",
    "        output_core_dims=[[\"time\",\"member\"]]    \n",
    "    )\n",
    "    \n",
    "    #some housekeeping\n",
    "    #re-organizing dimensions\n",
    "    temp=temp.transpose(\"time\",\"member\",\"latitude\",\"longitude\")\n",
    "    \n",
    "    #adding attributes so that the output dataset is CF compliant\n",
    "    temp.longitude.attrs={\n",
    "        \"units\":\"degrees_east\",\n",
    "        \"long_name\":\"longitude\",\n",
    "        \"axis\":\"X\",\n",
    "        \"standard_name\":\"longitude\" \n",
    "    }\n",
    "    temp.latitude.attrs={\n",
    "        \"units\":\"degrees_north\",\n",
    "        \"long_name\":\"latitude\",\n",
    "        \"axis\":\"Y\",\n",
    "        \"standard_name\":\"latitude\" \n",
    "    }\n",
    "    #appending to the list that stores outputs\n",
    "    fcstmoncalib.append(temp)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d34c18-177b-4510-ae5d-73e885db9466",
   "metadata": {},
   "source": [
    "### Finishing off the monthly process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a5dcf91-7af8-41db-9854-831fd579b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating outputs from individual lead times (so far stored in a list) into a single data array\n",
    "fcstmoncalib=xr.concat(fcstmoncalib, dim=\"time\")\n",
    "# making sure there is a correct sequencing of dates\n",
    "fcstmoncalib=fcstmoncalib.sortby(\"time\")\n",
    "# Since we are processing rainfall - negative values are not realistic, although they may emerge from the IoV calibration process\n",
    "# this makes sure negative values are not retained in the calibrated monthly data\n",
    "fcstmoncalibnoneg=fcstmoncalib.where(fcstmoncalib>0,0)\n",
    "fcstmoncalib=fcstmoncalibnoneg.where(~np.isnan(fcstmoncalib))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38e8d92-e06a-4689-90c1-20fd3a5f8281",
   "metadata": {},
   "source": [
    "Note that calibration is done on the entire available set of retro forecasts, including the current forecast, so the output array (fcstcalib) holds data for all years. Since we are interested only in the current forecast - we need to select only these data. It's a bit complicated, because we cannot just select by the nominal year and month of the current forecast..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eec37b7b-49ef-4e57-aa3a-a3ce47e72496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding out the first day of the current forecast\n",
    "fday=pd.to_datetime(\"{}-{}-{}\".format(fcstyear,fcstmonth,1))\n",
    "#finding out its last day\n",
    "lday=fday+pd.DateOffset(months=7)\n",
    "#selecting\n",
    "fcstmoncalib_current=fcstmoncalib.sel(time=slice(fday.strftime(\"%Y-%m-%d\"),lday.strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f852c0-d9cc-43a2-adce-c4f3f9bca732",
   "metadata": {},
   "source": [
    "At last we can save the output to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99b31897-96ce-4101-8ccc-9cde85cb2498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written /terra/projects/focus-africa/fcst_malawi/data/seasonal-calibrated/ECMWF/SEAS51/mon/malawi/pr/pr_mon_ECMWF_SEAS51_fcst-iov_202310.nc\n"
     ]
    }
   ],
   "source": [
    "#saving the selected data to output file\n",
    "fcstmoncalib_current.to_netcdf(calibratedfcstmon_file)\n",
    "print(\"written {}\".format(calibratedfcstmon_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3da505-3694-44d3-af47-6855abea7e8b",
   "metadata": {},
   "source": [
    "# Bias-correcting daily data\n",
    "\n",
    "Now that we have downscaled and calibrated data at monthly time scale, we can proceed with aligning daily data so that its monthly total aligns with calibrated monthly data.\n",
    "\n",
    "\n",
    "## Methodology\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Bias-correction of daily data is achieved by applying a bespoke bias-correction function over each grid point, separately for each month (lead time) of the forecast. This function implements the process described above and illustrated in Fig. 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92897dd4-3190-497d-ae18-69c7d05929ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqm_monadjust(_fcstref,_obsref,_fcstday,_fcstmon,_convcrit,_maxiter):\n",
    "    #making sure reference period does not have nans\n",
    "    _fref=_fcstref[~np.isnan(_fcstref)]\n",
    "    \n",
    "    #fitting ecdf to data in reference period\n",
    "    ecdf = ECDF(_fref.flatten())\n",
    "    \n",
    "    #preparing array to store the output\n",
    "    _fcstdaybc=_fcstday.copy()\n",
    "    _fcstdaybc[:]=np.nan\n",
    "\n",
    "    #iterating through members of the forecast ensemble\n",
    "    for m in range(_fcstday.shape[1]):\n",
    "        #extracting data for current member\n",
    "        _mfcstday=_fcstday[:,m]\n",
    "        _mfcstmon=_fcstmon[:,m]\n",
    "        \n",
    "        #deriving quantiles for daily forecast data\n",
    "        _mfcstday_quant=ecdf(_mfcstday.flatten())\n",
    "        \n",
    "        # finding rainfall values in observations that corresponds to given quantiles\n",
    "        # this a temporary value that will be further adjusted through iterative process \n",
    "        _mfcstdaybc=np.nanquantile(_obsref.flatten(), _mfcstday_quant)\n",
    "        # calculating correction factor, i.e. ratio of monthly total to sum of daily values\n",
    "        # this is temporary value that will be adjusted through iterative process\n",
    "        \n",
    "        _corfacmon=_mfcstmon/_mfcstdaybc.sum() #this is in terms of rainfall values\n",
    "        \n",
    "        # for stability of iterations, i.e. to avoid divergence of the iterative process, \n",
    "        # we set up minimum and maximum possible value of... \n",
    "        _quantcorfac_min,_quantcorfac_max=0.01,4\n",
    "        \n",
    "        if _corfacmon>1:\n",
    "            _quantcorfac_min=1\n",
    "            _quantcorfac=_quantcorfac_min\n",
    "        else:\n",
    "            _quantcorfac_max=1\n",
    "            _quantcorfac=_quantcorfac_max\n",
    "            \n",
    "        \n",
    "        #this is a special case when calibrated monthly total is small. Daily data are reset to 0 then.\n",
    "        if _mfcstmon<tracemon:\n",
    "            _corfacmon=1\n",
    "            _mfcstdaybc=_mfcstday.copy()\n",
    "            _mfcstdaybc[:]=0\n",
    "            \n",
    "        # implementing iterative adjustement until convergence criterion is reached\n",
    "        i=0\n",
    "        while np.abs(_corfacmon-1)>_convcrit:\n",
    "            i+=1\n",
    "            #calculating adjusted quantiles\n",
    "            _quant_adj=_mfcstday_quant*_quantcorfac\n",
    "            \n",
    "            #making sure adjusted quantiles are realistic\n",
    "            _quant_adj[_quant_adj>1]=1\n",
    "            \n",
    "            # calculating rainfall values for the adjusted quantiles\n",
    "            _mfcstdaybc=np.nanquantile(_obsref.flatten(), _quant_adj)\n",
    "            \n",
    "            # calculating adjustment needed for actual rainfall values\n",
    "            _corfacmon=_mfcstmon/_mfcstdaybc.sum()\n",
    "            \n",
    "            if _corfacmon>1:\n",
    "                # if corfacmon>1 then monthly total is too small, and daily values need to go up, \n",
    "                # for this we raise minimum possible value of quantile correcton factor\n",
    "                _quantcorfac_min=_quantcorfac\n",
    "            else:\n",
    "                #if corfacmon<1 then monthly total is too large, and daily values need to go down \n",
    "                # for this we reduce maximum possible value of quantile correction factor\n",
    "                _quantcorfac_max=_quantcorfac\n",
    "                \n",
    "            _quantcorfac=(_quantcorfac_min+_quantcorfac_max)/2\n",
    "            \n",
    "            if i==_maxiter:\n",
    "                print(\"maxiter reached\",_mfcstmon,_mfcstdaybc.sum(),_mfcstday.sum(),_corfacmon)\n",
    "                break\n",
    "        \n",
    "        _fcstdaybc[:,m]=_mfcstdaybc\n",
    "    return _fcstdaybc.reshape(*_fcstday.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37992bc2-c0f8-4f6c-aa6a-af44efcff2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading monthly reference data from: ../data/obs_malawi/pr_mon_obs.nc\n",
      "opening all daily files for given month (10)\n",
      "opening monthly calibrated forecast for given month (10)\n"
     ]
    }
   ],
   "source": [
    "print(\"reading monthly reference data from: {}\".format(referencemon_file))\n",
    "referencedayds=xr.open_dataset(referenceday_file)\n",
    "refday=referencedayds[variable]\n",
    "\n",
    "print(\"opening all daily files for given month ({})\".format(fcstmonth))\n",
    "fcstday=xr.open_mfdataset(harmonizedfcstday_files).load()[variable]\n",
    "\n",
    "print(\"opening monthly calibrated forecast for given month ({})\".format(fcstmonth))\n",
    "fcstmon=xr.open_dataset(calibratedfcstmon_file).load()[variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e91bfd2-4571-4cea-b586-fd07993b8c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias correcting...\n",
      "leadtime: 0\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n",
      "leadtime: 1\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n",
      "leadtime: 2\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n",
      "leadtime: 3\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n",
      "leadtime: 4\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n",
      "leadtime: 5\n",
      "(1023, 51, 20, 9) (1023, 20, 9) (31, 51, 20, 9) (1, 51, 20, 9)\n",
      "bias correcting...\n"
     ]
    }
   ],
   "source": [
    "print(\"bias correcting...\")\n",
    "maxiter=100\n",
    "convcrit=0.01\n",
    "\n",
    "fcstdaybc=[]\n",
    "for leadtime in range(6):\n",
    "    print(\"leadtime: {}\".format(leadtime))\n",
    "    \n",
    "    calendarmon=fcstday.time[leadtime].dt.month.data\n",
    "    \n",
    "    # selecting data for the target month only\n",
    "    refdayselected=refday.sel(time=refday.time.dt.month==calendarmon)\n",
    "    fcstdayselected=fcstday.sel(time=fcstday.time.dt.month==calendarmon)\n",
    "    \n",
    "    #selecting data for this month only - all months\n",
    "    #obsclim=obs.sel(time=obs.time.dt.month==tgtmonth)\n",
    "    #fcstdayclim=fcstdayall.sel(time=fcstdayall.time.dt.month==tgtmonth)\n",
    "    \n",
    "    #creating a placeholder for reference data\n",
    "#    refarray=fcstselected[:,0,:,:].copy(deep=True)\n",
    "    \n",
    "    #filling it with nan\n",
    "#    refarray[:]=np.nan\n",
    "    \n",
    "    # finding dates in reference data for which reforecast is available\n",
    "    overlap=[x for x in refdayselected.time.data if x in fcstdayselected.time.data]\n",
    "    \n",
    "    #this will have the same dimensions as fcstselected, and will be filled with reference data, when available, otherwise nan\n",
    "    refdayoverlap=refdayselected.sel(time=overlap)\n",
    "    \n",
    "    #this corresponds to the coverage of forecast, but has data only where obs data are available\n",
    "    #refarray.loc[dict(time=refsubset.time)]=refsubset\n",
    "\n",
    "    \n",
    "    \n",
    "    #selecting overlap of obs and forecast\n",
    "#    overlap=[x for x in obsclim.time.data if x in fcstdayclim.time.data]\n",
    "#    obsoverlap=obsclim.sel(time=overlap)\n",
    "#    (refsubset)\n",
    "\n",
    "    overlap=[x for x in fcstdayselected.time.data if x in refdayselected.time.data]\n",
    "#    overlap=[x for x in fcstdayclim.time.data if x in obsclim.time.data]\n",
    "#    fcstoverlap=fcstdayclim.sel(time=overlap)\n",
    "    fcstdayoverlap=fcstdayselected.sel(time=overlap)\n",
    "\n",
    "    \n",
    "    fcstdaytarget=fcstday.sel(time=\"{}-{}\".format(fcstyear,fcstmonth_code))\n",
    "    fcstmontarget=fcstmon.sel(time=\"{}-{}\".format(fcstyear,fcstmonth_code))\n",
    "        \n",
    "    #replacing values less than trace with random numbers. This is done in order to allow adjustement of the number of rain days.\n",
    "    rdata=np.copy(refdayoverlap)\n",
    "    rdata[:]=np.random.uniform(trace/10,trace,len(rdata.flatten())).reshape(*rdata.shape)\n",
    "    refdayoverlap=refdayoverlap.where((refdayoverlap<trace)==False, rdata)\n",
    "    del rdata\n",
    "\n",
    "    rdata=np.copy(fcstdayoverlap)\n",
    "    rdata[:]=np.random.uniform(trace/10,trace,len(rdata.flatten())).reshape(*rdata.shape)\n",
    "    fcstdayoverlap=fcstdayoverlap.where((fcstdayoverlap<trace)==False, rdata)\n",
    "    del rdata\n",
    "\n",
    "    rdata=np.copy(fcstdaytarget)\n",
    "    rdata[:]=np.random.uniform(trace/10,trace,len(rdata.flatten())).reshape(*rdata.shape)\n",
    "    fcstdaytgt=fcstdaytarget.where((fcstdaytarget<trace)==False, rdata)\n",
    "    del rdata\n",
    "\n",
    "    temp=xr.apply_ufunc(\n",
    "        qqm_monadjust, \n",
    "        fcstdayoverlap.load(),\n",
    "        refdayoverlap,\n",
    "        fcstdaytarget.load().rename({\"time\":\"time1\"}),\n",
    "        fcstmontarget.rename({\"time\":\"time2\"}),\n",
    "        convcrit,\n",
    "        maxiter,\n",
    "        input_core_dims=[[\"time\",\"member\"],[\"time\"],[\"time1\",\"member\"],[\"time2\",\"member\"],[],[]],\n",
    "        vectorize=True,\n",
    "        output_core_dims=[[\"time1\",\"member\"]]\n",
    "    )\n",
    "\n",
    "    fcstdaytargetbc=temp.rename({\"time1\":\"time\"}).transpose(\"time\",\"member\",\"latitude\",\"longitude\")\n",
    "    fcstdaybc.append(fcstdaytargetbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2af25-a3ae-4bf1-b072-4a462b330b09",
   "metadata": {},
   "source": [
    "### Finishing off the daily process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "719054a7-c21b-4903-ac63-16cf73a9576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily maximum 48.79999923706055\n",
      "written /terra/projects/focus-africa/fcst_malawi/data/seasonal-calibrated/ECMWF/SEAS51/day/malawi/pr/pr_day_ECMWF_SEAS51_fcst-iov_202310.nc\n"
     ]
    }
   ],
   "source": [
    "fcstdaybc=np.round(fcstdaybc,2)\n",
    "#fcstdaybc=xr.concat(fcstdaybc,\"time\")\n",
    "\n",
    "#Checking for unrealistic daily values\n",
    "maxval=np.max(fcstdaybc.data)\n",
    "print(\"daily maximum {}\".format(maxval))\n",
    "\n",
    "if maxval>350:\n",
    "    print(\"unrealistic max {}\".format(maxval))\n",
    "\n",
    "#saving the selected data to output file\n",
    "fcstdaybc.to_netcdf(calibratedfcstday_file)\n",
    "print(\"written {}\".format(calibratedfcstday_file))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3",
   "language": "python",
   "name": "conda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
